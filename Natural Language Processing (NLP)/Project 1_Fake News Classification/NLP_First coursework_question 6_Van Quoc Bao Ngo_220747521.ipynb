{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a237c25d",
   "metadata": {},
   "source": [
    "# Question 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c22f92bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "import csv                               # csv reader\n",
    "from sklearn.svm import LinearSVC\n",
    "!pip install nltk\n",
    "from nltk.classify import SklearnClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import precision_recall_fscore_support # to report on precision and recall\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ce46ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    \"\"\"Load data from a tab-separated file and append it to raw_data.\"\"\"\n",
    "    with open(path, encoding='utf-8') as f: #add 'encoding = utf-8' to original load_data function to avoid loading error\n",
    "        reader = csv.reader(f, delimiter='\\t')\n",
    "        for line in reader:\n",
    "            if line[0] == \"Id\":  # skip header\n",
    "                continue\n",
    "            (label, text) = parse_data_line(line)\n",
    "            raw_data.append((text, label))\n",
    "\n",
    "def split_and_preprocess_data(percentage):\n",
    "    \"\"\"Split the data between train_data and test_data according to the percentage\n",
    "    and performs the preprocessing.\"\"\"\n",
    "    num_samples = len(raw_data)\n",
    "    num_training_samples = int((percentage * num_samples))\n",
    "    for (text, label) in raw_data[:num_training_samples]:\n",
    "        train_data.append((to_feature_vector(pre_process(text)),label))\n",
    "    for (text, label) in raw_data[num_training_samples:]:\n",
    "        test_data.append((to_feature_vector(pre_process(text)),label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2691a2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_label(label):\n",
    "    \"\"\"Converts the multiple classes into two,\n",
    "    making it a binary distinction between fake news and real.\"\"\"\n",
    "    #return label\n",
    "    # Converting the multiclass labels to binary label\n",
    "    labels_map = {\n",
    "        'true': 'REAL',\n",
    "        'mostly-true': 'REAL',\n",
    "        'half-true': 'REAL',\n",
    "        'false': 'FAKE',\n",
    "        'barely-true': 'FAKE',\n",
    "        'pants-fire': 'FAKE'\n",
    "    }\n",
    "    return labels_map[label]\n",
    "\n",
    "\n",
    "def parse_data_line(data_line):\n",
    "    # Should return a tuple of the label as just FAKE or REAL and the statement\n",
    "    # e.g. (label, statement)\n",
    "    \n",
    "    # the function input (data_line) should be a list, then subset the list with index 1 to get the 'label' data\n",
    "    label = convert_label(data_line[1])\n",
    "    # the same approach can be applied to extract 'text' data with index 2\n",
    "    text = data_line[2]\n",
    "    return (label, text) #return the tuple (label, text), which has the same order as in the 'load_data' function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a9b6efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(text): # optimal preprocess: str.split() + token normalization\n",
    "    # Should return a list of tokens\n",
    "    # DESCRIBE YOUR METHOD IN WORDS\n",
    "    tokens_list = []\n",
    "    token = text.split()\n",
    "    for i in token:\n",
    "        i = i.lower()\n",
    "        tokens_list.append(i)\n",
    "    return tokens_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5a6b46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_feature_dict = {} # A global dictionary of features\n",
    "\n",
    "def to_feature_vector(tokens): # optimal feature extract: set min token frequency and add non-text count as new feature\n",
    "    feature_dict = {} # Created an empty dictionary (local feature dict) to store the vocab\n",
    "    # Should return a dictionary containing features as keys, and weights as values\n",
    "    # DESCRIBE YOUR METHOD IN WORDS\n",
    "    nontext_count = 0\n",
    "    for i in tokens: # Loop the input tokens. \n",
    "        #For each token, look up in the global dictionary to see if it exists\n",
    "        if i not in global_feature_dict: # If no, then assign value 1 for that token and add it to the global dictionary\n",
    "            global_feature_dict[i] = 1\n",
    "        else: # If yes, then take the values (weights) to add 1 more (values + 1) and update it into the global dictionary\n",
    "            global_feature_dict[i] = float(global_feature_dict[i] + 1)\n",
    "        #For each token, look up in the feature dictionary to see if it exists (same approach as above)\n",
    "        if i not in feature_dict:  # If no, then assign value 1 for that token and add it to the feature dictionary\n",
    "            feature_dict[i] = 1\n",
    "        else: # If yes, then take the values (weights) to add 1 more (values + 1) and update it into the feature dictionary\n",
    "            feature_dict[i] = float(feature_dict[i] + 1)\n",
    "        if not i.isalpha():\n",
    "            nontext_count += 1\n",
    "    for a in feature_dict.copy():\n",
    "        if global_feature_dict[a] < 2:\n",
    "                del feature_dict[a]\n",
    "    feature_dict['nontext_count'] = nontext_count\n",
    "    return feature_dict # Return the feature dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09f0001b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING AND VALIDATING OUR CLASSIFIER\n",
    "\n",
    "def train_classifier(data):\n",
    "    #print(\"Training Classifier...\")\n",
    "    pipeline =  Pipeline([('svc', LinearSVC(C = 0.007964824120603023, max_iter=100000))])\n",
    "    return SklearnClassifier(pipeline).train(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79cd5098",
   "metadata": {},
   "outputs": [],
   "source": [
    "#solution\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from random import shuffle # Import shuffle method\n",
    "\n",
    "def cross_validate(dataset, folds):\n",
    "    #shuffle(dataset) # Shuffle the input dataset\n",
    "    results = [] # Create an empty list to store the result after running the function\n",
    "    fold_size = int(len(dataset)/folds) + 1 # Set number of folds to run\n",
    "    accuracy_rate = [] # Create list to store accuracy\n",
    "    for i in range(0,len(dataset),int(fold_size)):\n",
    "        # insert code here that trains and tests on the 10 folds of data in the dataset\n",
    "        #print(\"Fold start on items %d - %d\" % (i, i+fold_size))\n",
    "        # FILL IN THE METHOD HERE\n",
    "        # Set up validation dataset in cross-validation with its size being equal to 1 fold_size\n",
    "        validation = dataset[i : i+fold_size]\n",
    "        # Set up trainset in cross-validation by excluding the validation set from the input dataset, and take the rest\n",
    "        train = dataset[:i] + dataset[i+fold_size:]\n",
    "        # Train the classifier with the pipeline function created with the model initialiser (LinearSVC in this case)\n",
    "        classifier = train_classifier(train)\n",
    "        # Extract the ground-truth labels from the validation dataset\n",
    "        yval_true = [t[1] for t in validation]\n",
    "        #Â Implement the trained model into validation set and get predicted labels\n",
    "        yval_pred = predict_labels([x[0] for x in validation], classifier)\n",
    "        # Calculate precision, recall and fscore from the prediction, compared to ground truth\n",
    "        final_scores = precision_recall_fscore_support(yval_true, yval_pred, average='weighted', zero_division=0) # evaluate\n",
    "        # Calculate model accuracy\n",
    "        accuracy = accuracy_calculate(yval_true, yval_pred)\n",
    "        # Append the value to the list created at the top for storage\n",
    "        results.append(final_scores)\n",
    "        accuracy_rate.append(accuracy)\n",
    "    # Convert list 'results' to array for easy further calculation\n",
    "    cv_results = np.asarray(results)\n",
    "    # Calculate the average precision score after k-fold time running\n",
    "    avg_precision = np.mean(cv_results[:, 0], axis = 0)\n",
    "    # Calculate the average recall score after k-fold time running\n",
    "    avg_recall = np.mean(cv_results[:, 1], axis = 0)\n",
    "    # Calculate the average f1 score after k-fold time running\n",
    "    avg_fscore = np.mean(cv_results[:, 2], axis = 0)\n",
    "    # Calculate the average accuracy after k-fold time running\n",
    "    avg_accuracy = np.mean(accuracy_rate)\n",
    "    print('\\n')\n",
    "    print('After folding throughout cross-val process, the average score of precision - recall - f1score - accuracy is: ')\n",
    "    return avg_precision, avg_recall, avg_fscore, avg_accuracy #return all the values needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dfa2c220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREDICTING LABELS GIVEN A CLASSIFIER\n",
    "\n",
    "def predict_labels(samples, classifier):\n",
    "    \"\"\"Assuming preprocessed samples, return their predicted labels from the classifier model.\"\"\"\n",
    "    return classifier.classify_many(samples)\n",
    "\n",
    "def predict_label_from_raw(sample, classifier):\n",
    "    \"\"\"Assuming raw text, return its predicted label from the classifier model.\"\"\"\n",
    "    return classifier.classify(to_feature_vector(preProcess(reviewSample)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09426b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the model accuracy given a classifier\n",
    "def accuracy_calculate(y_true, y_pred):\n",
    "    correct = 0\n",
    "    for a, b in zip(y_true, y_pred):\n",
    "        if a==b: correct += 1\n",
    "        else: pass\n",
    "    return correct/len(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3914c89b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now 0 rawData, 0 trainData, 0 testData\n",
      "Preparing the dataset...\n",
      "Now 10240 rawData, 0 trainData, 0 testData\n",
      "Preparing training and test data...\n",
      "After split, 10240 rawData, 8192 trainData, 2048 testData\n",
      "Training Samples: \n",
      "8192\n",
      "Features: \n",
      "20066\n"
     ]
    }
   ],
   "source": [
    "# MAIN\n",
    "\n",
    "# loading reviews\n",
    "# initialize global lists that will be appended to by the methods below\n",
    "raw_data = []          # the filtered data from the dataset file\n",
    "train_data = []        # the pre-processed training data as a percentage of the total dataset\n",
    "test_data = []         # the pre-processed test data as a percentage of the total dataset\n",
    "\n",
    "\n",
    "# references to the data files\n",
    "data_file_path = 'fake_news.tsv'\n",
    "\n",
    "# Do the actual stuff (i.e. call the functions we've made)\n",
    "# We parse the dataset and put it in a raw data list\n",
    "print(\"Now %d rawData, %d trainData, %d testData\" % (len(raw_data), len(train_data), len(test_data)),\n",
    "      \"Preparing the dataset...\",sep='\\n')\n",
    "\n",
    "load_data(data_file_path) \n",
    "\n",
    "# We split the raw dataset into a set of training data and a set of test data (80/20)\n",
    "# You do the cross validation on the 80% (training data)\n",
    "# We print the number of training samples and the number of features before the split\n",
    "print(\"Now %d rawData, %d trainData, %d testData\" % (len(raw_data), len(train_data), len(test_data)),\n",
    "      \"Preparing training and test data...\",sep='\\n')\n",
    "\n",
    "split_and_preprocess_data(0.8)\n",
    "\n",
    "# We print the number of training samples and the number of features after the split\n",
    "print(\"After split, %d rawData, %d trainData, %d testData\" % (len(raw_data), len(train_data), len(test_data)),\n",
    "      \"Training Samples: \", len(train_data), \"Features: \", len(global_feature_dict), sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3e8c6ca",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "After folding throughout cross-val process, the average score of precision - recall - f1score - accuracy is: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6020411143379807, 0.6080517842124233, 0.598107828827725, 0.6080517842124233)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validate(train_data, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60f06cc",
   "metadata": {},
   "source": [
    "## try adding 'subject'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44614613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "After folding throughout cross-val process, the average score of precision - recall - f1score - accuracy is: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6033591709839616,\n",
       " 0.6093119542306534,\n",
       " 0.5999688513222489,\n",
       " 0.6093119542306534)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parse_data_line(data_line):\n",
    "    # the function input (data_line) should be a list, then subset the list with index 1 to get the 'label' data\n",
    "    label = convert_label(data_line[1])\n",
    "    # the same approach can be applied to extract 'text' data with index 2\n",
    "    text = data_line[2]\n",
    "    subject = data_line[3]\n",
    "    speaker = data_line[4]\n",
    "    speaker_title = data_line[5]\n",
    "    state = data_line[6]\n",
    "    party = data_line[7]\n",
    "    barely_true = data_line[8]\n",
    "    false = data_line[9]\n",
    "    half_true = data_line[10]\n",
    "    mostly_true = data_line[11]\n",
    "    pants_on_fire = data_line[12]\n",
    "    context = data_line[13]\n",
    "    return (label, text , subject) #return the tuple (label, text), which has the same order as in the 'load_data' function\n",
    "\n",
    "def load_data(path):\n",
    "    \"\"\"Load data from a tab-separated file and append it to raw_data.\"\"\"\n",
    "    with open(path, encoding='utf-8') as f: #add 'encoding = utf-8' to original load_data function to avoid loading error\n",
    "        reader = csv.reader(f, delimiter='\\t')\n",
    "        for line in reader:\n",
    "            if line[0] == \"Id\":  # skip header\n",
    "                continue\n",
    "            elif len(line) < 14:\n",
    "                continue\n",
    "            (label, text , a) = parse_data_line(line)\n",
    "            raw_data.append((text, label, a))\n",
    "\n",
    "def split_and_preprocess_data(percentage):\n",
    "    \"\"\"Split the data between train_data and test_data according to the percentage\n",
    "    and performs the preprocessing.\"\"\"\n",
    "    num_samples = len(raw_data)\n",
    "    num_training_samples = int((percentage * num_samples))\n",
    "    for (text, label, a) in raw_data[:num_training_samples]:\n",
    "        new_text = text + ' ' + a\n",
    "        train_data.append((to_feature_vector(pre_process(new_text)),label))\n",
    "    for (text, label, a) in raw_data[num_training_samples:]:\n",
    "        new_text = text + ' ' + a\n",
    "        test_data.append((to_feature_vector(pre_process(new_text)),label))\n",
    "        \n",
    "#MAIN\n",
    "raw_data = []         \n",
    "train_data = []        \n",
    "test_data = []        \n",
    "\n",
    "data_file_path = 'fake_news.tsv'\n",
    "\n",
    "load_data(data_file_path) \n",
    "\n",
    "split_and_preprocess_data(0.8)\n",
    "\n",
    "cross_validate(train_data, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16009bc9",
   "metadata": {},
   "source": [
    "**Adding 'subject' improves the model performance ==> agree to add 'subject' as a new feature and use it in later test**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769ce9a8",
   "metadata": {},
   "source": [
    "## try adding 'speaker'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a07ae44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "After folding throughout cross-val process, the average score of precision - recall - f1score - accuracy is: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6253115238232914,\n",
       " 0.6297018970189703,\n",
       " 0.6207918593539445,\n",
       " 0.6297018970189702)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parse_data_line(data_line):\n",
    "    # the function input (data_line) should be a list, then subset the list with index 1 to get the 'label' data\n",
    "    label = convert_label(data_line[1])\n",
    "    # the same approach can be applied to extract 'text' data with index 2\n",
    "    text = data_line[2]\n",
    "    subject = data_line[3]\n",
    "    speaker = data_line[4]\n",
    "    speaker_title = data_line[5]\n",
    "    state = data_line[6]\n",
    "    party = data_line[7]\n",
    "    barely_true = data_line[8]\n",
    "    false = data_line[9]\n",
    "    half_true = data_line[10]\n",
    "    mostly_true = data_line[11]\n",
    "    pants_on_fire = data_line[12]\n",
    "    context = data_line[13]\n",
    "    return (label, text , subject, speaker) #return the tuple (label, text), which has the same order as in the 'load_data' function\n",
    "\n",
    "def load_data(path):\n",
    "    \"\"\"Load data from a tab-separated file and append it to raw_data.\"\"\"\n",
    "    with open(path, encoding='utf-8') as f: #add 'encoding = utf-8' to original load_data function to avoid loading error\n",
    "        reader = csv.reader(f, delimiter='\\t')\n",
    "        for line in reader:\n",
    "            if line[0] == \"Id\":  # skip header\n",
    "                continue\n",
    "            elif len(line) < 14:\n",
    "                continue\n",
    "            (label, text , a, b) = parse_data_line(line)\n",
    "            raw_data.append((text, label, a, b))\n",
    "\n",
    "def split_and_preprocess_data(percentage):\n",
    "    \"\"\"Split the data between train_data and test_data according to the percentage\n",
    "    and performs the preprocessing.\"\"\"\n",
    "    num_samples = len(raw_data)\n",
    "    num_training_samples = int((percentage * num_samples))\n",
    "    for (text, label, a, b) in raw_data[:num_training_samples]:\n",
    "        new_text = text + ' ' + a + ' ' + b\n",
    "        train_data.append((to_feature_vector(pre_process(new_text)),label))\n",
    "    for (text, label, a, b) in raw_data[num_training_samples:]:\n",
    "        new_text = text + ' ' + a + ' ' + b\n",
    "        test_data.append((to_feature_vector(pre_process(new_text)),label))\n",
    "        \n",
    "#MAIN\n",
    "raw_data = []         \n",
    "train_data = []        \n",
    "test_data = []        \n",
    "\n",
    "data_file_path = 'fake_news.tsv'\n",
    "\n",
    "load_data(data_file_path) \n",
    "\n",
    "split_and_preprocess_data(0.8)\n",
    "\n",
    "cross_validate(train_data, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd41a171",
   "metadata": {},
   "source": [
    "**Adding 'speaker' improves the model performance ==> agree to add 'speaker' as a new feature and use it in later test**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0261ad2",
   "metadata": {},
   "source": [
    "## try adding 'speaker job title'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec1684e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "After folding throughout cross-val process, the average score of precision - recall - f1score - accuracy is: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.625518037399394, 0.6300828063836195, 0.6217800944443649, 0.6300828063836192)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parse_data_line(data_line):\n",
    "    # the function input (data_line) should be a list, then subset the list with index 1 to get the 'label' data\n",
    "    label = convert_label(data_line[1])\n",
    "    # the same approach can be applied to extract 'text' data with index 2\n",
    "    text = data_line[2]\n",
    "    subject = data_line[3]\n",
    "    speaker = data_line[4]\n",
    "    speaker_title = data_line[5]\n",
    "    state = data_line[6]\n",
    "    party = data_line[7]\n",
    "    barely_true = data_line[8]\n",
    "    false = data_line[9]\n",
    "    half_true = data_line[10]\n",
    "    mostly_true = data_line[11]\n",
    "    pants_on_fire = data_line[12]\n",
    "    context = data_line[13]\n",
    "    return (label, text , subject, speaker, speaker_title) #return the tuple (label, text), which has the same order as in the 'load_data' function\n",
    "\n",
    "def load_data(path):\n",
    "    \"\"\"Load data from a tab-separated file and append it to raw_data.\"\"\"\n",
    "    with open(path, encoding='utf-8') as f: #add 'encoding = utf-8' to original load_data function to avoid loading error\n",
    "        reader = csv.reader(f, delimiter='\\t')\n",
    "        for line in reader:\n",
    "            if line[0] == \"Id\":  # skip header\n",
    "                continue\n",
    "            elif len(line) < 14:\n",
    "                continue\n",
    "            (label, text , a, b, c) = parse_data_line(line)\n",
    "            raw_data.append((text, label, a, b, c))\n",
    "\n",
    "def split_and_preprocess_data(percentage):\n",
    "    \"\"\"Split the data between train_data and test_data according to the percentage\n",
    "    and performs the preprocessing.\"\"\"\n",
    "    num_samples = len(raw_data)\n",
    "    num_training_samples = int((percentage * num_samples))\n",
    "    for (text, label, a, b, c) in raw_data[:num_training_samples]:\n",
    "        new_text = text + ' ' + a + ' ' + b + ' ' + c\n",
    "        train_data.append((to_feature_vector(pre_process(new_text)),label))\n",
    "    for (text, label, a, b, c) in raw_data[num_training_samples:]:\n",
    "        new_text = text + ' ' + a + ' ' + b + ' ' + c\n",
    "        test_data.append((to_feature_vector(pre_process(new_text)),label))\n",
    "        \n",
    "#MAIN\n",
    "raw_data = []         \n",
    "train_data = []        \n",
    "test_data = []        \n",
    "\n",
    "data_file_path = 'fake_news.tsv'\n",
    "\n",
    "load_data(data_file_path) \n",
    "\n",
    "split_and_preprocess_data(0.8)\n",
    "\n",
    "cross_validate(train_data, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4365c9ee",
   "metadata": {},
   "source": [
    "**Adding 'speaker_job_title' improves the model performance ==> agree to add 'speaker_job_title' as a new feature and use it in later test**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87dd5265",
   "metadata": {},
   "source": [
    "## try adding 'state_info\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "494f4fd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "After folding throughout cross-val process, the average score of precision - recall - f1score - accuracy is: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6280273987469114,\n",
       " 0.6324074074074074,\n",
       " 0.6248137623173349,\n",
       " 0.6324074074074074)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parse_data_line(data_line):\n",
    "    # the function input (data_line) should be a list, then subset the list with index 1 to get the 'label' data\n",
    "    label = convert_label(data_line[1])\n",
    "    # the same approach can be applied to extract 'text' data with index 2\n",
    "    text = data_line[2]\n",
    "    subject = data_line[3]\n",
    "    speaker = data_line[4]\n",
    "    speaker_title = data_line[5]\n",
    "    state = data_line[6]\n",
    "    party = data_line[7]\n",
    "    barely_true = data_line[8]\n",
    "    false = data_line[9]\n",
    "    half_true = data_line[10]\n",
    "    mostly_true = data_line[11]\n",
    "    pants_on_fire = data_line[12]\n",
    "    context = data_line[13]\n",
    "    return (label, text , subject, speaker, speaker_title , state) #return the tuple (label, text), which has the same order as in the 'load_data' function\n",
    "\n",
    "def load_data(path):\n",
    "    \"\"\"Load data from a tab-separated file and append it to raw_data.\"\"\"\n",
    "    with open(path, encoding='utf-8') as f: #add 'encoding = utf-8' to original load_data function to avoid loading error\n",
    "        reader = csv.reader(f, delimiter='\\t')\n",
    "        for line in reader:\n",
    "            if line[0] == \"Id\":  # skip header\n",
    "                continue\n",
    "            elif len(line) < 14:\n",
    "                continue\n",
    "            (label, text , a, b, c, d) = parse_data_line(line)\n",
    "            raw_data.append((text, label, a, b, c, d))\n",
    "\n",
    "def split_and_preprocess_data(percentage):\n",
    "    \"\"\"Split the data between train_data and test_data according to the percentage\n",
    "    and performs the preprocessing.\"\"\"\n",
    "    num_samples = len(raw_data)\n",
    "    num_training_samples = int((percentage * num_samples))\n",
    "    for (text, label, a, b, c, d) in raw_data[:num_training_samples]:\n",
    "        new_text = text + ' ' + a + ' ' + b + ' ' + c + ' ' + d\n",
    "        train_data.append((to_feature_vector(pre_process(new_text)),label))\n",
    "    for (text, label, a, b, c, d) in raw_data[num_training_samples:]:\n",
    "        new_text = text + ' ' + a + ' ' + b + ' ' + c + ' ' + d\n",
    "        test_data.append((to_feature_vector(pre_process(new_text)),label))\n",
    "        \n",
    "#MAIN\n",
    "raw_data = []         \n",
    "train_data = []        \n",
    "test_data = []        \n",
    "\n",
    "data_file_path = 'fake_news.tsv'\n",
    "\n",
    "load_data(data_file_path) \n",
    "\n",
    "split_and_preprocess_data(0.8)\n",
    "\n",
    "cross_validate(train_data, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48bfb92",
   "metadata": {},
   "source": [
    "**Adding 'state_info' improves the model performance ==> agree to add 'state_info' as a new feature and use it in later test**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00f98dc",
   "metadata": {},
   "source": [
    "## try adding 'party affiliation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "22b2917c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "After folding throughout cross-val process, the average score of precision - recall - f1score - accuracy is: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6291005653286841,\n",
       " 0.6332625715146041,\n",
       " 0.6265810659238757,\n",
       " 0.6332625715146041)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parse_data_line(data_line):\n",
    "    # the function input (data_line) should be a list, then subset the list with index 1 to get the 'label' data\n",
    "    label = convert_label(data_line[1])\n",
    "    # the same approach can be applied to extract 'text' data with index 2\n",
    "    text = data_line[2]\n",
    "    subject = data_line[3]\n",
    "    speaker = data_line[4]\n",
    "    speaker_title = data_line[5]\n",
    "    state = data_line[6]\n",
    "    party = data_line[7]\n",
    "    barely_true = data_line[8]\n",
    "    false = data_line[9]\n",
    "    half_true = data_line[10]\n",
    "    mostly_true = data_line[11]\n",
    "    pants_on_fire = data_line[12]\n",
    "    context = data_line[13]\n",
    "    return (label, text , subject, speaker, speaker_title , state, party) #return the tuple (label, text), which has the same order as in the 'load_data' function\n",
    "\n",
    "def load_data(path):\n",
    "    \"\"\"Load data from a tab-separated file and append it to raw_data.\"\"\"\n",
    "    with open(path, encoding='utf-8') as f: #add 'encoding = utf-8' to original load_data function to avoid loading error\n",
    "        reader = csv.reader(f, delimiter='\\t')\n",
    "        for line in reader:\n",
    "            if line[0] == \"Id\":  # skip header\n",
    "                continue\n",
    "            elif len(line) < 14:\n",
    "                continue\n",
    "            (label, text , a, b, c, d, e) = parse_data_line(line)\n",
    "            raw_data.append((text, label, a, b, c, d ,e))\n",
    "\n",
    "def split_and_preprocess_data(percentage):\n",
    "    \"\"\"Split the data between train_data and test_data according to the percentage\n",
    "    and performs the preprocessing.\"\"\"\n",
    "    num_samples = len(raw_data)\n",
    "    num_training_samples = int((percentage * num_samples))\n",
    "    for (text, label, a, b, c, d, e) in raw_data[:num_training_samples]:\n",
    "        new_text = text + ' ' + a + ' ' + b + ' ' + c + ' ' + d + ' ' + e\n",
    "        train_data.append((to_feature_vector(pre_process(new_text)),label))\n",
    "    for (text, label, a, b, c, d, e) in raw_data[num_training_samples:]:\n",
    "        new_text = text + ' ' + a + ' ' + b + ' ' + c + ' ' + d + ' ' + e\n",
    "        test_data.append((to_feature_vector(pre_process(new_text)),label))\n",
    "        \n",
    "#MAIN\n",
    "raw_data = []         \n",
    "train_data = []        \n",
    "test_data = []        \n",
    "\n",
    "data_file_path = 'fake_news.tsv'\n",
    "\n",
    "load_data(data_file_path) \n",
    "\n",
    "split_and_preprocess_data(0.8)\n",
    "\n",
    "cross_validate(train_data, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba17a0d5",
   "metadata": {},
   "source": [
    "**Adding 'party_affiliation' improves the model performance ==> agree to add 'party_affiliation' as a new feature and use it in later test**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb98051",
   "metadata": {},
   "source": [
    "## try adding 'total barely true counts'\n",
    "this would be tokenized as 'barely_true', weighted by the value of 'total_barely_true_counts': **value * 'barely_true'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "30667e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "After folding throughout cross-val process, the average score of precision - recall - f1score - accuracy is: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6449585907368421, 0.648383017163505, 0.642911387555957, 0.648383017163505)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parse_data_line(data_line):\n",
    "    # the function input (data_line) should be a list, then subset the list with index 1 to get the 'label' data\n",
    "    label = convert_label(data_line[1])\n",
    "    # the same approach can be applied to extract 'text' data with index 2\n",
    "    text = data_line[2]\n",
    "    subject = data_line[3]\n",
    "    speaker = data_line[4]\n",
    "    speaker_title = data_line[5]\n",
    "    state = data_line[6]\n",
    "    party = data_line[7]\n",
    "    barely_true = data_line[8]\n",
    "    false = data_line[9]\n",
    "    half_true = data_line[10]\n",
    "    mostly_true = data_line[11]\n",
    "    pants_on_fire = data_line[12]\n",
    "    context = data_line[13]\n",
    "    return (label, text , subject, speaker, speaker_title , state, party, barely_true) #return the tuple (label, text), which has the same order as in the 'load_data' function\n",
    "\n",
    "def load_data(path):\n",
    "    \"\"\"Load data from a tab-separated file and append it to raw_data.\"\"\"\n",
    "    with open(path, encoding='utf-8') as f: #add 'encoding = utf-8' to original load_data function to avoid loading error\n",
    "        reader = csv.reader(f, delimiter='\\t')\n",
    "        for line in reader:\n",
    "            if line[0] == \"Id\":  # skip header\n",
    "                continue\n",
    "            elif len(line) < 14:\n",
    "                continue\n",
    "            (label, text , a, b, c, d, e, f) = parse_data_line(line)\n",
    "            raw_data.append((text, label, a, b, c, d ,e, f))\n",
    "\n",
    "def split_and_preprocess_data(percentage):\n",
    "    \"\"\"Split the data between train_data and test_data according to the percentage\n",
    "    and performs the preprocessing.\"\"\"\n",
    "    num_samples = len(raw_data)\n",
    "    num_training_samples = int((percentage * num_samples))\n",
    "    for (text, label, a, b, c, d, e, f) in raw_data[:num_training_samples]:\n",
    "        new_text = text + ' ' + a + ' ' + b + ' ' + c + ' ' + d + ' ' + e + ' ' + int(f)*'barely_true'\n",
    "        train_data.append((to_feature_vector(pre_process(new_text)),label))\n",
    "    for (text, label, a, b, c, d, e, f) in raw_data[num_training_samples:]:\n",
    "        new_text = text + ' ' + a + ' ' + b + ' ' + c + ' ' + d + ' ' + e + ' ' + int(f)*'barely_true'\n",
    "        test_data.append((to_feature_vector(pre_process(new_text)),label))\n",
    "        \n",
    "#MAIN\n",
    "raw_data = []         \n",
    "train_data = []        \n",
    "test_data = []        \n",
    "\n",
    "data_file_path = 'fake_news.tsv'\n",
    "\n",
    "load_data(data_file_path) \n",
    "\n",
    "split_and_preprocess_data(0.8)\n",
    "\n",
    "cross_validate(train_data, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d506d1ab",
   "metadata": {},
   "source": [
    "**Adding 'total_barely_true_counts' improves the model performance ==> agree to add 'total_barely_true_counts' as a new feature and use it in later test**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be649fd",
   "metadata": {},
   "source": [
    "## try adding 'total false counts'\n",
    "this would be tokenized as 'false', weighted by the value of 'total_false_counts': **value * 'false'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d17ee4c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "After folding throughout cross-val process, the average score of precision - recall - f1score - accuracy is: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6648219488955837, 0.6673215898825656, 0.662893803225596, 0.6673215898825655)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parse_data_line(data_line):\n",
    "    # the function input (data_line) should be a list, then subset the list with index 1 to get the 'label' data\n",
    "    label = convert_label(data_line[1])\n",
    "    # the same approach can be applied to extract 'text' data with index 2\n",
    "    text = data_line[2]\n",
    "    subject = data_line[3]\n",
    "    speaker = data_line[4]\n",
    "    speaker_title = data_line[5]\n",
    "    state = data_line[6]\n",
    "    party = data_line[7]\n",
    "    barely_true = data_line[8]\n",
    "    false = data_line[9]\n",
    "    half_true = data_line[10]\n",
    "    mostly_true = data_line[11]\n",
    "    pants_on_fire = data_line[12]\n",
    "    context = data_line[13]\n",
    "    return (label, text , subject, speaker, speaker_title , state, party, barely_true, false) #return the tuple (label, text), which has the same order as in the 'load_data' function\n",
    "\n",
    "def load_data(path):\n",
    "    \"\"\"Load data from a tab-separated file and append it to raw_data.\"\"\"\n",
    "    with open(path, encoding='utf-8') as f: #add 'encoding = utf-8' to original load_data function to avoid loading error\n",
    "        reader = csv.reader(f, delimiter='\\t')\n",
    "        for line in reader:\n",
    "            if line[0] == \"Id\":  # skip header\n",
    "                continue\n",
    "            elif len(line) < 14:\n",
    "                continue\n",
    "            (label, text , a, b, c, d, e, f, g) = parse_data_line(line)\n",
    "            raw_data.append((text, label, a, b, c, d ,e, f, g))\n",
    "\n",
    "def split_and_preprocess_data(percentage):\n",
    "    \"\"\"Split the data between train_data and test_data according to the percentage\n",
    "    and performs the preprocessing.\"\"\"\n",
    "    num_samples = len(raw_data)\n",
    "    num_training_samples = int((percentage * num_samples))\n",
    "    for (text, label, a, b, c, d, e, f, g) in raw_data[:num_training_samples]:\n",
    "        new_text = text + ' ' + a + ' ' + b + ' ' + c + ' ' + d + ' ' + e + ' ' + int(f)*'barely_true' + ' ' + int(g)*'false'\n",
    "        train_data.append((to_feature_vector(pre_process(new_text)),label))\n",
    "    for (text, label, a, b, c, d, e, f, g) in raw_data[num_training_samples:]:\n",
    "        new_text = text + ' ' + a + ' ' + b + ' ' + c + ' ' + d + ' ' + e + ' ' + int(f)*'barely_true' + ' ' + int(g)*'false'\n",
    "        test_data.append((to_feature_vector(pre_process(new_text)),label))\n",
    "        \n",
    "#MAIN\n",
    "raw_data = []         \n",
    "train_data = []        \n",
    "test_data = []        \n",
    "\n",
    "data_file_path = 'fake_news.tsv'\n",
    "\n",
    "load_data(data_file_path) \n",
    "\n",
    "split_and_preprocess_data(0.8)\n",
    "\n",
    "cross_validate(train_data, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2be027",
   "metadata": {},
   "source": [
    "**Adding 'total_false_counts' improves the model performance ==> agree to add 'total_false_counts' as a new feature and use it in later test**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a17d87",
   "metadata": {},
   "source": [
    "## try adding 'total half true counts'\n",
    "this would be tokenized as 'half_true', weighted by the value of 'total_half_true_counts': **value * 'half_true'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d82b5261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "After folding throughout cross-val process, the average score of precision - recall - f1score - accuracy is: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6803477441695904,\n",
       " 0.6824510689551342,\n",
       " 0.6787633537392791,\n",
       " 0.6824510689551342)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parse_data_line(data_line):\n",
    "    # the function input (data_line) should be a list, then subset the list with index 1 to get the 'label' data\n",
    "    label = convert_label(data_line[1])\n",
    "    # the same approach can be applied to extract 'text' data with index 2\n",
    "    text = data_line[2]\n",
    "    subject = data_line[3]\n",
    "    speaker = data_line[4]\n",
    "    speaker_title = data_line[5]\n",
    "    state = data_line[6]\n",
    "    party = data_line[7]\n",
    "    barely_true = data_line[8]\n",
    "    false = data_line[9]\n",
    "    half_true = data_line[10]\n",
    "    mostly_true = data_line[11]\n",
    "    pants_on_fire = data_line[12]\n",
    "    context = data_line[13]\n",
    "    return (label, text , subject, speaker, speaker_title , state, party, barely_true, false, half_true) #return the tuple (label, text), which has the same order as in the 'load_data' function\n",
    "\n",
    "def load_data(path):\n",
    "    \"\"\"Load data from a tab-separated file and append it to raw_data.\"\"\"\n",
    "    with open(path, encoding='utf-8') as f: #add 'encoding = utf-8' to original load_data function to avoid loading error\n",
    "        reader = csv.reader(f, delimiter='\\t')\n",
    "        for line in reader:\n",
    "            if line[0] == \"Id\":  # skip header\n",
    "                continue\n",
    "            elif len(line) < 14:\n",
    "                continue\n",
    "            (label, text , a, b, c, d, e, f, g, h) = parse_data_line(line)\n",
    "            raw_data.append((text, label, a, b, c, d ,e, f, g, h))\n",
    "\n",
    "def split_and_preprocess_data(percentage):\n",
    "    \"\"\"Split the data between train_data and test_data according to the percentage\n",
    "    and performs the preprocessing.\"\"\"\n",
    "    num_samples = len(raw_data)\n",
    "    num_training_samples = int((percentage * num_samples))\n",
    "    for (text, label, a, b, c, d, e, f, g, h) in raw_data[:num_training_samples]:\n",
    "        new_text = text + ' ' + a + ' ' + b + ' ' + c + ' ' + d + ' ' + e + ' ' + int(f)*'barely_true' + ' ' + int(g)*'false' + ' ' + int(h)*'half_true'\n",
    "        train_data.append((to_feature_vector(pre_process(new_text)),label))\n",
    "    for (text, label, a, b, c, d, e, f, g, h) in raw_data[num_training_samples:]:\n",
    "        new_text = text + ' ' + a + ' ' + b + ' ' + c + ' ' + d + ' ' + e + ' ' + int(f)*'barely_true' + ' ' + int(g)*'false' + ' ' + int(h)*'half_true'\n",
    "        test_data.append((to_feature_vector(pre_process(new_text)),label))\n",
    "        \n",
    "#MAIN\n",
    "raw_data = []         \n",
    "train_data = []        \n",
    "test_data = []        \n",
    "\n",
    "data_file_path = 'fake_news.tsv'\n",
    "\n",
    "load_data(data_file_path) \n",
    "\n",
    "split_and_preprocess_data(0.8)\n",
    "\n",
    "cross_validate(train_data, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6d59d0",
   "metadata": {},
   "source": [
    "**Adding 'total_half_true_counts' improves the model performance ==> agree to add 'total_half_true_counts' as a new feature and use it in later test**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dade27da",
   "metadata": {},
   "source": [
    "## try adding 'total mostly true counts'\n",
    "this would be tokenized as 'mostly_true', weighted by the value of 'total_mostly_true_counts': **value * 'mostly_true'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "916077f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "After folding throughout cross-val process, the average score of precision - recall - f1score - accuracy is: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6951906957819507, 0.6967359229147847, 0.693008206784248, 0.6967359229147847)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parse_data_line(data_line):\n",
    "    # the function input (data_line) should be a list, then subset the list with index 1 to get the 'label' data\n",
    "    label = convert_label(data_line[1])\n",
    "    # the same approach can be applied to extract 'text' data with index 2\n",
    "    text = data_line[2]\n",
    "    subject = data_line[3]\n",
    "    speaker = data_line[4]\n",
    "    speaker_title = data_line[5]\n",
    "    state = data_line[6]\n",
    "    party = data_line[7]\n",
    "    barely_true = data_line[8]\n",
    "    false = data_line[9]\n",
    "    half_true = data_line[10]\n",
    "    mostly_true = data_line[11]\n",
    "    pants_on_fire = data_line[12]\n",
    "    context = data_line[13]\n",
    "    return (label, text , subject, speaker, speaker_title , state, party, barely_true, false, half_true, mostly_true) #return the tuple (label, text), which has the same order as in the 'load_data' function\n",
    "\n",
    "def load_data(path):\n",
    "    \"\"\"Load data from a tab-separated file and append it to raw_data.\"\"\"\n",
    "    with open(path, encoding='utf-8') as f: #add 'encoding = utf-8' to original load_data function to avoid loading error\n",
    "        reader = csv.reader(f, delimiter='\\t')\n",
    "        for line in reader:\n",
    "            if line[0] == \"Id\":  # skip header\n",
    "                continue\n",
    "            elif len(line) < 14:\n",
    "                continue\n",
    "            (label, text , a, b, c, d, e, f, g, h, i) = parse_data_line(line)\n",
    "            raw_data.append((text, label, a, b, c, d ,e, f, g, h, i))\n",
    "\n",
    "def split_and_preprocess_data(percentage):\n",
    "    \"\"\"Split the data between train_data and test_data according to the percentage\n",
    "    and performs the preprocessing.\"\"\"\n",
    "    num_samples = len(raw_data)\n",
    "    num_training_samples = int((percentage * num_samples))\n",
    "    for (text, label, a, b, c, d, e, f, g, h, i) in raw_data[:num_training_samples]:\n",
    "        new_text = text + ' ' + a + ' ' + b + ' ' + c + ' ' + d + ' ' + e + ' ' + int(f)*'barely_true' + ' ' + int(g)*'false' + ' ' + int(h)*'half_true' + ' ' + int(i)*'mostly_true'\n",
    "        train_data.append((to_feature_vector(pre_process(new_text)),label))\n",
    "    for (text, label, a, b, c, d, e, f, g, h, i) in raw_data[num_training_samples:]:\n",
    "        new_text = text + ' ' + a + ' ' + b + ' ' + c + ' ' + d + ' ' + e + ' ' + int(f)*'barely_true' + ' ' + int(g)*'false' + ' ' + int(h)*'half_true' + ' ' + int(i)*'mostly_true'\n",
    "        test_data.append((to_feature_vector(pre_process(new_text)),label))\n",
    "        \n",
    "#MAIN\n",
    "raw_data = []         \n",
    "train_data = []        \n",
    "test_data = []        \n",
    "\n",
    "data_file_path = 'fake_news.tsv'\n",
    "\n",
    "load_data(data_file_path) \n",
    "\n",
    "split_and_preprocess_data(0.8)\n",
    "\n",
    "cross_validate(train_data, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa8dca5",
   "metadata": {},
   "source": [
    "**Adding 'total_mostly_true_counts' improves the model performance ==> agree to add 'total_mostly_true_counts' as a new feature and use it in later test**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b54d8cc",
   "metadata": {},
   "source": [
    "## try adding 'total pants on fire counts'\n",
    "this would be tokenized as 'pants_on_fire', weighted by the value of 'total_pants_on_fire_counts': **value * 'pants_on_fire'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "911ac533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "After folding throughout cross-val process, the average score of precision - recall - f1score - accuracy is: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7027500582915027,\n",
       " 0.7041960252935862,\n",
       " 0.7011088368027659,\n",
       " 0.7041960252935862)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parse_data_line(data_line):\n",
    "    # the function input (data_line) should be a list, then subset the list with index 1 to get the 'label' data\n",
    "    label = convert_label(data_line[1])\n",
    "    # the same approach can be applied to extract 'text' data with index 2\n",
    "    text = data_line[2]\n",
    "    subject = data_line[3]\n",
    "    speaker = data_line[4]\n",
    "    speaker_title = data_line[5]\n",
    "    state = data_line[6]\n",
    "    party = data_line[7]\n",
    "    barely_true = data_line[8]\n",
    "    false = data_line[9]\n",
    "    half_true = data_line[10]\n",
    "    mostly_true = data_line[11]\n",
    "    pants_on_fire = data_line[12]\n",
    "    context = data_line[13]\n",
    "    return (label, text , subject, speaker, speaker_title , state, party, barely_true, false, half_true, mostly_true, pants_on_fire) #return the tuple (label, text), which has the same order as in the 'load_data' function\n",
    "\n",
    "def load_data(path):\n",
    "    \"\"\"Load data from a tab-separated file and append it to raw_data.\"\"\"\n",
    "    with open(path, encoding='utf-8') as f: #add 'encoding = utf-8' to original load_data function to avoid loading error\n",
    "        reader = csv.reader(f, delimiter='\\t')\n",
    "        for line in reader:\n",
    "            if line[0] == \"Id\":  # skip header\n",
    "                continue\n",
    "            elif len(line) < 14:\n",
    "                continue\n",
    "            (label, text , a, b, c, d, e, f, g, h, i, m) = parse_data_line(line)\n",
    "            raw_data.append((text, label, a, b, c, d ,e, f, g, h, i, m))\n",
    "\n",
    "def split_and_preprocess_data(percentage):\n",
    "    \"\"\"Split the data between train_data and test_data according to the percentage\n",
    "    and performs the preprocessing.\"\"\"\n",
    "    num_samples = len(raw_data)\n",
    "    num_training_samples = int((percentage * num_samples))\n",
    "    for (text, label, a, b, c, d, e, f, g, h, i, m) in raw_data[:num_training_samples]:\n",
    "        new_text = text + ' ' + a + ' ' + b + ' ' + c + ' ' + d + ' ' + e + ' ' + int(f)*'barely_true' + ' ' + int(g)*'false' + ' ' + int(h)*'half_true' + ' ' + int(i)*'mostly_true' + ' ' + int(m)*'pants_on_fire'\n",
    "        train_data.append((to_feature_vector(pre_process(new_text)),label))\n",
    "    for (text, label, a, b, c, d, e, f, g, h, i, m) in raw_data[num_training_samples:]:\n",
    "        new_text = text + ' ' + a + ' ' + b + ' ' + c + ' ' + d + ' ' + e + ' ' + int(f)*'barely_true' + ' ' + int(g)*'false' + ' ' + int(h)*'half_true' + ' ' + int(i)*'mostly_true' + ' ' + int(m)*'pants_on_fire'\n",
    "        test_data.append((to_feature_vector(pre_process(new_text)),label))\n",
    "        \n",
    "#MAIN\n",
    "raw_data = []         \n",
    "train_data = []        \n",
    "test_data = []        \n",
    "\n",
    "data_file_path = 'fake_news.tsv'\n",
    "\n",
    "load_data(data_file_path) \n",
    "\n",
    "split_and_preprocess_data(0.8)\n",
    "\n",
    "cross_validate(train_data, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63fb3790",
   "metadata": {},
   "source": [
    "**Adding 'total_pants_on_fire_counts' improves the model performance ==> agree to add 'total_pants_on_fire_counts' as a new feature and use it in later test**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a2a870",
   "metadata": {},
   "source": [
    "## try adding 'context'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6d625ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "After folding throughout cross-val process, the average score of precision - recall - f1score - accuracy is: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.701559412165166, 0.7033212887684432, 0.700293969178744, 0.7033212887684432)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parse_data_line(data_line):\n",
    "    # the function input (data_line) should be a list, then subset the list with index 1 to get the 'label' data\n",
    "    label = convert_label(data_line[1])\n",
    "    # the same approach can be applied to extract 'text' data with index 2\n",
    "    text = data_line[2]\n",
    "    subject = data_line[3]\n",
    "    speaker = data_line[4]\n",
    "    speaker_title = data_line[5]\n",
    "    state = data_line[6]\n",
    "    party = data_line[7]\n",
    "    barely_true = data_line[8]\n",
    "    false = data_line[9]\n",
    "    half_true = data_line[10]\n",
    "    mostly_true = data_line[11]\n",
    "    pants_on_fire = data_line[12]\n",
    "    context = data_line[13]\n",
    "    return (label, text , subject, speaker, speaker_title , state, party, barely_true, false, half_true, mostly_true, pants_on_fire, context) #return the tuple (label, text), which has the same order as in the 'load_data' function\n",
    "\n",
    "def load_data(path):\n",
    "    \"\"\"Load data from a tab-separated file and append it to raw_data.\"\"\"\n",
    "    with open(path, encoding='utf-8') as f: #add 'encoding = utf-8' to original load_data function to avoid loading error\n",
    "        reader = csv.reader(f, delimiter='\\t')\n",
    "        for line in reader:\n",
    "            if line[0] == \"Id\":  # skip header\n",
    "                continue\n",
    "            elif len(line) < 14:\n",
    "                continue\n",
    "            (label, text , a, b, c, d, e, f, g, h, i, m, n) = parse_data_line(line)\n",
    "            raw_data.append((text, label, a, b, c, d ,e, f, g, h, i, m, n))\n",
    "\n",
    "def split_and_preprocess_data(percentage):\n",
    "    \"\"\"Split the data between train_data and test_data according to the percentage\n",
    "    and performs the preprocessing.\"\"\"\n",
    "    num_samples = len(raw_data)\n",
    "    num_training_samples = int((percentage * num_samples))\n",
    "    for (text, label, a, b, c, d, e, f, g, h, i, m, n) in raw_data[:num_training_samples]:\n",
    "        new_text = text + ' ' + a + ' ' + b + ' ' + c + ' ' + d + ' ' + e + ' ' + int(f)*'barely_true' + ' ' + int(g)*'false' + ' ' + int(h)*'half_true' + ' ' + int(i)*'mostly_true' + ' ' + int(m)*'pants_on_fire' + ' ' + n\n",
    "        train_data.append((to_feature_vector(pre_process(new_text)),label))\n",
    "    for (text, label, a, b, c, d, e, f, g, h, i, m, n) in raw_data[num_training_samples:]:\n",
    "        new_text = text + ' ' + a + ' ' + b + ' ' + c + ' ' + d + ' ' + e + ' ' + int(f)*'barely_true' + ' ' + int(g)*'false' + ' ' + int(h)*'half_true' + ' ' + int(i)*'mostly_true' + ' ' + int(m)*'pants_on_fire' + ' ' + n\n",
    "        test_data.append((to_feature_vector(pre_process(new_text)),label))\n",
    "        \n",
    "#MAIN\n",
    "raw_data = []         \n",
    "train_data = []        \n",
    "test_data = []        \n",
    "\n",
    "data_file_path = 'fake_news.tsv'\n",
    "\n",
    "load_data(data_file_path) \n",
    "\n",
    "split_and_preprocess_data(0.8)\n",
    "\n",
    "cross_validate(train_data, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f797acba",
   "metadata": {},
   "source": [
    "**Adding 'context' does not improve the model performance ==> skip 'context'**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fcf6b93",
   "metadata": {},
   "source": [
    "# Final Model\n",
    "## After testing around, I decide to add these attributes as new features, besides the existing ones:\n",
    "1. subject\n",
    "2. speaker\n",
    "3. speaker_job_title\n",
    "4. state_info\n",
    "5. party_affiliation\n",
    "6. total_barely_true_counts\n",
    "7. total_false_counts\n",
    "8. total_half_true_counts\n",
    "9. total_mostly_true_counts\n",
    "10. total_pants_on_fire_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9c0105c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "After folding throughout cross-val process, the average score of precision - recall - f1score - accuracy is: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7027500582915027,\n",
       " 0.7041960252935862,\n",
       " 0.7011088368027659,\n",
       " 0.7041960252935862)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#final model with selected features and modified preprocessing and adjusted parameters (taken from question 5)\n",
    "def parse_data_line(data_line):\n",
    "    # the function input (data_line) should be a list, then subset the list with index 1 to get the 'label' data\n",
    "    label = convert_label(data_line[1])\n",
    "    # the same approach can be applied to extract 'text' data with index 2\n",
    "    text = data_line[2]\n",
    "    subject = data_line[3]\n",
    "    speaker = data_line[4]\n",
    "    speaker_title = data_line[5]\n",
    "    state = data_line[6]\n",
    "    party = data_line[7]\n",
    "    barely_true = data_line[8]\n",
    "    false = data_line[9]\n",
    "    half_true = data_line[10]\n",
    "    mostly_true = data_line[11]\n",
    "    pants_on_fire = data_line[12]\n",
    "    context = data_line[13]\n",
    "    return (label, text , subject, speaker, speaker_title , state, party, barely_true, false, half_true, mostly_true, pants_on_fire) #return the tuple (label, text), which has the same order as in the 'load_data' function\n",
    "\n",
    "def load_data(path):\n",
    "    \"\"\"Load data from a tab-separated file and append it to raw_data.\"\"\"\n",
    "    with open(path, encoding='utf-8') as f: #add 'encoding = utf-8' to original load_data function to avoid loading error\n",
    "        reader = csv.reader(f, delimiter='\\t')\n",
    "        for line in reader:\n",
    "            if line[0] == \"Id\":  # skip header\n",
    "                continue\n",
    "            elif len(line) < 14:\n",
    "                continue\n",
    "            (label, text , a, b, c, d, e, f, g, h, i, m) = parse_data_line(line)\n",
    "            raw_data.append((text, label, a, b, c, d ,e, f, g, h, i, m))\n",
    "\n",
    "def split_and_preprocess_data(percentage):\n",
    "    \"\"\"Split the data between train_data and test_data according to the percentage\n",
    "    and performs the preprocessing.\"\"\"\n",
    "    num_samples = len(raw_data)\n",
    "    num_training_samples = int((percentage * num_samples))\n",
    "    for (text, label, a, b, c, d, e, f, g, h, i, m) in raw_data[:num_training_samples]:\n",
    "        new_text = text + ' ' + a + ' ' + b + ' ' + c + ' ' + d + ' ' + e + ' ' + int(f)*'barely_true' + ' ' + int(g)*'false' + ' ' + int(h)*'half_true' + ' ' + int(i)*'mostly_true' + ' ' + int(m)*'pants_on_fire'\n",
    "        train_data.append((to_feature_vector(pre_process(new_text)),label))\n",
    "    for (text, label, a, b, c, d, e, f, g, h, i, m) in raw_data[num_training_samples:]:\n",
    "        new_text = text + ' ' + a + ' ' + b + ' ' + c + ' ' + d + ' ' + e + ' ' + int(f)*'barely_true' + ' ' + int(g)*'false' + ' ' + int(h)*'half_true' + ' ' + int(i)*'mostly_true' + ' ' + int(m)*'pants_on_fire'\n",
    "        test_data.append((to_feature_vector(pre_process(new_text)),label))\n",
    "        \n",
    "#MAIN\n",
    "raw_data = []         \n",
    "train_data = []        \n",
    "test_data = []        \n",
    "\n",
    "data_file_path = 'fake_news.tsv'\n",
    "\n",
    "load_data(data_file_path) \n",
    "\n",
    "split_and_preprocess_data(0.8)\n",
    "\n",
    "cross_validate(train_data, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8687290",
   "metadata": {},
   "source": [
    "# Apply the model on test set to evaluate the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8dbae87e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'the': 2.0, 'bush': 1, 'tax': 1, 'cuts': 1, 'helped': 1, 'to': 1, 'create': 1, 'a': 1, 'substantial': 1, 'part': 1, 'of': 1, 'deficit.': 1, 'bush-administration,deficit,taxes': 1, 'dennis-kucinich': 1, 'u.s.': 1, 'representative': 1, 'ohio': 1, 'democrat': 1, 'barely_true': 1, 'falsefalsefalse': 1, 'half_truehalf_truehalf_truehalf_true': 1, 'mostly_truemostly_truemostly_truemostly_truemostly_truemostly_true': 1, 'nontext_count': 7}, 'REAL')\n",
      "Done training!\n",
      "Precision: 0.684335\n",
      "Recall: 0.685059\n",
      "F Score:0.681368\n"
     ]
    }
   ],
   "source": [
    "# Finally, check the accuracy of your classifier by training on all the traning data\n",
    "# and testing on the test set\n",
    "# Will only work once all functions are complete\n",
    "functions_complete = True  # set to True once you're happy with your methods for cross val\n",
    "if functions_complete:\n",
    "    print(test_data[0])   # have a look at the first test data instance\n",
    "    classifier = train_classifier(train_data)  # train the classifier\n",
    "    test_true = [t[1] for t in test_data]   # get the ground-truth labels from the data\n",
    "    test_pred = predict_labels([x[0] for x in test_data], classifier)  #Â classify the test data to get predicted labels\n",
    "    final_scores = precision_recall_fscore_support(test_true, test_pred, average='weighted') # evaluate\n",
    "    print(\"Done training!\")\n",
    "    print(\"Precision: %f\\nRecall: %f\\nF Score:%f\" % final_scores[:3])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
